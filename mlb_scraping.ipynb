{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error de general\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\urllib3\\contrib\\pyopenssl.py\", line 453, in wrap_socket\n",
      "    cnx.do_handshake()\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\OpenSSL\\SSL.py\", line 1915, in do_handshake\n",
      "    self._raise_ssl_error(self._ssl, result)\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\OpenSSL\\SSL.py\", line 1647, in _raise_ssl_error\n",
      "    _raise_current_error()\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\OpenSSL\\_util.py\", line 54, in exception_from_error_queue\n",
      "    raise exception_type(errors)\n",
      "OpenSSL.SSL.Error: [('SSL routines', 'ssl3_get_record', 'wrong version number')]\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py\", line 600, in urlopen\n",
      "    chunked=chunked)\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py\", line 343, in _make_request\n",
      "    self._validate_conn(conn)\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py\", line 839, in _validate_conn\n",
      "    conn.connect()\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\urllib3\\connection.py\", line 344, in connect\n",
      "    ssl_context=context)\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\urllib3\\util\\ssl_.py\", line 357, in ssl_wrap_socket\n",
      "    return context.wrap_socket(sock)\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\urllib3\\contrib\\pyopenssl.py\", line 459, in wrap_socket\n",
      "    raise ssl.SSLError('bad handshake: %r' % e)\n",
      "ssl.SSLError: (\"bad handshake: Error([('SSL routines', 'ssl3_get_record', 'wrong version number')])\",)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\requests\\adapters.py\", line 449, in send\n",
      "    timeout=timeout\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py\", line 638, in urlopen\n",
      "    _stacktrace=sys.exc_info()[2])\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\urllib3\\util\\retry.py\", line 398, in increment\n",
      "    raise MaxRetryError(_pool, url, error or ResponseError(cause))\n",
      "urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='65.8.248.23', port=443): Max retries exceeded with url: /leagues/MLB/2018-schedule.shtml (Caused by SSLError(SSLError(\"bad handshake: Error([('SSL routines', 'ssl3_get_record', 'wrong version number')])\")))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-118-da5b830af0c4>\", line 38, in load_mlb_schedule\n",
      "    reps = requests.get(link)\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\requests\\api.py\", line 75, in get\n",
      "    return request('get', url, params=params, **kwargs)\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\requests\\api.py\", line 60, in request\n",
      "    return session.request(method=method, url=url, **kwargs)\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\requests\\sessions.py\", line 533, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\requests\\sessions.py\", line 646, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"C:\\Anaconda3\\lib\\site-packages\\requests\\adapters.py\", line 514, in send\n",
      "    raise SSLError(e, request=request)\n",
      "requests.exceptions.SSLError: HTTPSConnectionPool(host='65.8.248.23', port=443): Max retries exceeded with url: /leagues/MLB/2018-schedule.shtml (Caused by SSLError(SSLError(\"bad handshake: Error([('SSL routines', 'ssl3_get_record', 'wrong version number')])\")))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import unittest\n",
    "import time\n",
    "import sys\n",
    "import os\n",
    "from os import path\n",
    "import traceback\n",
    "import requests\n",
    "\n",
    "from bs4 import BeautifulSoup , Comment \n",
    "from lxml import etree\n",
    "\n",
    "#test\n",
    "def newtag(bs : BeautifulSoup, tagn : str ,text: str) :\n",
    "    tag = bs.new_tag(tagn)\n",
    "    tag.string = text \n",
    "    return tag\n",
    "\n",
    "def load_mlb_schedule(year):\n",
    "    \n",
    "    #BASE_URL = \"https://www.baseball-reference.com\" \n",
    "    BASE_URL = \"https://65.8.248.23\"\n",
    "    link = f\"{BASE_URL}/leagues/MLB/{year}-schedule.shtml\"\n",
    "    schedule = []\n",
    "    gdir = str(year)\n",
    "    dummycnt = 1\n",
    "    \n",
    "    try:\n",
    "        #crear el repots\n",
    "        if not (path.isdir(gdir)):\n",
    "            os.mkdir(gdir)\n",
    "\n",
    "        #carga el archivo de los datos\n",
    "        #file = open(\"mlb_game.txt\",\"a\")\n",
    "\n",
    "        # cargar la pagina\n",
    "        time.sleep(3)\n",
    "        tic = time.perf_counter()\n",
    "        reps = requests.get(link)\n",
    "        toc = time.perf_counter()\n",
    "        \n",
    "        #leer el contenido de la pagina\n",
    "        html = reps.content\n",
    "        if (html):  \n",
    "            print(f\"Schedule {toc - tic+1:0.4} seconds url: {link}\")\n",
    "            soup = BeautifulSoup(html,'html.parser')\n",
    "            div_section_wrapper = soup.find_all('div',class_= 'section_wrapper')\n",
    "            div_section_content = div_section_wrapper[0].find_all('div',class_='section_content')\n",
    "            divs = div_section_content[0].find_all('div')\n",
    "            print(len(divs))\n",
    "            for div in divs:\n",
    "                ps = div.find_all('p', class_=\"game\")\n",
    "                for p in ps:\n",
    "                    ems = p.find_all('em')\n",
    "                    dict = {}\n",
    "                    link,archivo,fecha = ''\n",
    "                    for em in ems:\n",
    "                        if dummycnt == 1 :\n",
    "                            link =  f\"{BASE_URL}{em.a.get('href')}\"\n",
    "                            archivo = f\"sessons//{gdir}\"\n",
    "                            fecha =  link.split('/')[5][3:12]   \n",
    "                        if dummycnt % 2 == 0 :\n",
    "                            link =  f\"{BASE_URL}{em.a.get('href')}\"\n",
    "                            archivo = f\"sessons//{gdir}\"\n",
    "                            fecha =  link.split('/')[5][3:12]   \n",
    "                        dict ={'link' : link, 'archivo' : archivo, 'fecha' : fecha }                    \n",
    "                        schedule.append(dict)                     \n",
    "                        dummycnt += 1   \n",
    "        return schedule\n",
    "    except ValueError:\n",
    "            print(\"Error de Valor\")\n",
    "            traceback.print_exception(*sys.exc_info())\n",
    "            return schedule\n",
    "    except:    \n",
    "            print(\"Error de general\") \n",
    "            traceback.print_exception(*sys.exc_info())   \n",
    "            return schedule                     \n",
    "\n",
    "def load_mlb_games(link,archivo,fecha):\n",
    "    \n",
    "\n",
    "    try:\n",
    "\n",
    "        #carga el archivo de los datos\n",
    "        file = open(str(folder)+'//'+link.split('/')[5],'a')\n",
    "        gamedate = link.split('/')[5][3:12]                                    \n",
    "\n",
    "        # cargar la pagina\n",
    "        time.sleep(3)\n",
    "        tic = time.perf_counter()\n",
    "        reps = requests.get(link)\n",
    "        toc = time.perf_counter()\n",
    "        \n",
    "        #leer el contenido de la pagina\n",
    "        html = reps.content\n",
    "        if (html):  \n",
    "            print(f\"Process {toc - tic+1:0.4} seconds url: {link}\")\n",
    "            soup = BeautifulSoup(html,'html.parser')\n",
    "           \n",
    "            #codigo de los equipos\n",
    "            uls = soup.find_all('ul',class_='in_list')\n",
    "            teams = uls[0].find_all('a')\n",
    "            home  = teams[1]['href'].split('/')[2]\n",
    "            visi  = teams[2]['href'].split('/')[2]\n",
    "\n",
    "            #saca el tag escondido\n",
    "            comments = soup.find_all(text=lambda text:isinstance(text, Comment))\n",
    "            htm = str([htm for htm in comments if \"div_play_by_play\" in htm]);\n",
    "            if(htm):                          \n",
    "                div = BeautifulSoup(htm,'html.parser')\n",
    "                tbody  = div.find_all(\"tbody\")\n",
    "                rows = tbody[0].find_all('tr', class_ =['top_inning','bottom_inning'])\n",
    "               \n",
    "                for row in rows:\n",
    "                    if row != ['']:\n",
    "                       thtext = row.find_all('th')[0].text                     \n",
    "                       row.insert(0, newtag(div,'td',thtext))\n",
    "                       row.insert(0, newtag(div,'td',visi))\n",
    "                       row.insert(0, newtag(div,'td',home))\n",
    "                       row.insert(0, newtag(div,'td',gamedate))                     \n",
    "\n",
    "                      # print(row)\n",
    "                       cols=row.find_all('td')\n",
    "                       cols=[\" \".join(x.text.replace(',','|').upper().split()) for x in cols]\n",
    "                       file.write(\" , \".join(cols)+'\\n')\n",
    "                       #print(cols)  \n",
    "            file.close  \n",
    "    except ValueError:\n",
    "            file.close \n",
    "            print(\"Error de Valor\")\n",
    "            traceback.print_exception(*sys.exc_info())\n",
    "    except:    \n",
    "            file.close                     \n",
    "            print(\"Error de general\") \n",
    "            traceback.print_exception(*sys.exc_info())   \n",
    "\n",
    "load_mlb_schedule(2018) \n",
    "#score  = 'https://www.baseball-reference.com/boxes/CHN/CHN201810020.shtml'                                            \n",
    "#load_mlb_games(score,2018)\n",
    "                                \n",
    "#for score in load_mlb_schedule(2018):\n",
    "    #load_mlb_games(score,2018)\n",
    "                                \n",
    "                               \n",
    "                                \n",
    "                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CHN201810020.shtml'"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
