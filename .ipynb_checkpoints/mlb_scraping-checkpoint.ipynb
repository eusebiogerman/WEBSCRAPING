{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wXcA3kna0jcW",
    "outputId": "8ec3c5c6-8a99-4ccc-aa2e-bae62325a351"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Schedule 1.605 seconds url: https://www.baseball-reference.com//leagues/MLB/2010-schedule.shtml\n",
      "Downloading Games 2010 |▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐                                  | 33.80%  Error de general : load_mlb_games\n",
      "Downloading Games 2010 |▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐                                  | 33.88%  Error de general : load_mlb_games\n",
      "Downloading Games 2010 |▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐                                  | 33.96%  Error de general : load_mlb_games\n",
      "Downloading Games 2010 |▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐                                 | 34.05%  Error de general : load_mlb_games\n",
      "Downloading Games 2010 |▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐                                 | 34.13%  Error de general : load_mlb_games\n",
      "Downloading Games 2010 |▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐                                 | 34.21%  Error de general : load_mlb_games\n",
      "Downloading Games 2010 |▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐                                 | 34.29%  Error de general : load_mlb_games\n",
      "Downloading Games 2010 |▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐                                 | 34.38%  Error de general : load_mlb_games\n",
      "Downloading Games 2010 |▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐                                 | 34.46%  Error de general : load_mlb_games\n",
      "Downloading Games 2010 |▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐                                 | 34.54%  Error de general : load_mlb_games\n",
      "Downloading Games 2010 |▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐            | 77.06%  Error de general : load_mlb_games\n",
      "Downloading Games 2010 |▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐            | 77.14%  Error de general : load_mlb_games\n",
      "Downloading Games 2010 |▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐            | 77.22%  Error de general : load_mlb_games\n",
      "Downloading Games 2010 |▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐            | 77.30%  Error de general : load_mlb_games\n",
      "Downloading Games 2010 |▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐            | 77.38%  Error de general : load_mlb_games\n",
      "Downloading Games 2010 |▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐| 100.00%  \n",
      "Schedule 1.373 seconds url: https://www.baseball-reference.com//leagues/MLB/2011-schedule.shtml\n",
      "Downloading Games 2011 |▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐| 100.00%  \n",
      "Schedule 1.353 seconds url: https://www.baseball-reference.com//leagues/MLB/2012-schedule.shtml\n",
      "Downloading Games 2012 |▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐| 100.00%  \n",
      "Schedule 1.337 seconds url: https://www.baseball-reference.com//leagues/MLB/2013-schedule.shtml\n",
      "Downloading Games 2013 |▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐| 100.00%  \n",
      "Schedule 1.329 seconds url: https://www.baseball-reference.com//leagues/MLB/2014-schedule.shtml\n",
      "Downloading Games 2014 |▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐▐| 100.00%  \n"
     ]
    }
   ],
   "source": [
    "import unittest\n",
    "import time\n",
    "import sys\n",
    "import os\n",
    "from os import path\n",
    "import traceback\n",
    "import requests\n",
    "import logging\n",
    "\n",
    "from console_progressbar import ProgressBar\n",
    "from bs4 import BeautifulSoup , Comment \n",
    "from lxml import etree\n",
    "\n",
    "#test\n",
    "def log(text,file):\n",
    "    file = open(file,'a')\n",
    "    file.write(text)\n",
    "\n",
    "def newtag(bs : BeautifulSoup, tagn : str ,text: str) :\n",
    "    tag = bs.new_tag(tagn)\n",
    "    tag.string = text \n",
    "    return tag\n",
    "\n",
    "def get_trace_value(trace):\n",
    "    exc_type, exc_value, exc_tb = trace \n",
    "    plist = traceback.format_exception(exc_type, exc_value, exc_tb)\n",
    "    trace = ''\n",
    "    for p in plist:\n",
    "        trace = trace + str(p) + '/n'\n",
    "    return trace\n",
    "\n",
    "def load_mlb_schedule(year):\n",
    "    \n",
    "    #BASE_URL = \"https://www.baseball-reference.com\" \n",
    "    BASE_URL = \"https://www.baseball-reference.com/\"\n",
    "    link = f\"{BASE_URL}/leagues/MLB/{year}-schedule.shtml\"\n",
    "    link2 = ''\n",
    "    archivo = ''\n",
    "    fecha = ''\n",
    "    schedule = []\n",
    "    gdir = str(year)\n",
    "    dummycnt = 1\n",
    "    \n",
    "    try:\n",
    "        #crear el repots\n",
    "        if not (path.isdir('sessons')):\n",
    "            os.mkdir('sessons')\n",
    "\n",
    "        #carga el archivo de los datos\n",
    "        #file = open(\"mlb_game.txt\",\"a\")\n",
    "\n",
    "        # cargar la pagina\n",
    "        time.sleep(3)\n",
    "        tic = time.perf_counter()\n",
    "        reps = requests.get(link)\n",
    "        toc = time.perf_counter()\n",
    "        \n",
    "        #leer el contenido de la pagina\n",
    "        html = reps.content\n",
    "        if (html):  \n",
    "            print(f\"Schedule {toc - tic+1:0.4} seconds url: {link}\")\n",
    "            soup = BeautifulSoup(html,'html.parser')\n",
    "            div_section_wrapper = soup.find_all('div',class_= 'section_wrapper')\n",
    "            div_section_content = div_section_wrapper[0].find_all('div',class_='section_content')\n",
    "            divs = div_section_content[0].find_all('div')\n",
    "            for div in divs:\n",
    "                ps = div.find_all('p', class_=\"game\")\n",
    "                for p in ps:\n",
    "                    ems = p.find_all('em')\n",
    "                    dict = {}\n",
    "                    for em in ems:\n",
    "                        fecha = em.a.get('href').split('/')[3][3:12]\n",
    "                        archivo = f\"sessons/{gdir}.txt\"\n",
    "                        link2 =  f\"{BASE_URL}{em.a.get('href')}\"\n",
    "                        if dummycnt == 1 :\n",
    "                           dict ={'link' : link2, 'archivo' : archivo, 'fecha' : fecha }  \n",
    "                           schedule.append(dict)\n",
    "                        if dummycnt % 2 == 0 :\n",
    "                           dict ={'link' : link2, 'archivo' : archivo, 'fecha' : fecha }                    \n",
    "                           schedule.append(dict)                     \n",
    "                        dummycnt += 1   \n",
    "        return schedule\n",
    "    except ValueError:\n",
    "            print(\"Error de Valor\")\n",
    "            log(get_trace_value(sys.exc_info()),logfile)\n",
    "            return schedule\n",
    "    except:    \n",
    "            print(\"Error de general\") \n",
    "            log(get_trace_value(sys.exc_info()),logfile)   \n",
    "            return schedule                     \n",
    "\n",
    "\n",
    "def load_mlb_games(link, archivo, gamedate):\n",
    "    \n",
    "    logfile = archivo.split('/')[1].replace('txt','log')\n",
    "    logfile = archivo.split('/')[0] +'/'+ logfile\n",
    "    try:\n",
    "\n",
    "        #carga el archivo de los datos\n",
    "        file = open(archivo, 'a')\n",
    "\n",
    "        # cargar la pagina\n",
    "        time.sleep(3)\n",
    "        tic = time.perf_counter()\n",
    "        reps = requests.get(link)\n",
    "        toc = time.perf_counter()\n",
    "        \n",
    "        #leer el contenido de la pagina\n",
    "        html = reps.content\n",
    "        if (html):  \n",
    "            log(f\"Process {toc - tic+1:0.4} seconds url: {link}\",logfile)\n",
    "            soup = BeautifulSoup(html,'html.parser')\n",
    "           \n",
    "            #codigo de los equipos\n",
    "            uls = soup.find_all('ul',class_='in_list')\n",
    "            teams = uls[0].find_all('a')\n",
    "            home  = teams[1]['href'].split('/')[2]\n",
    "            visi  = teams[2]['href'].split('/')[2]\n",
    "\n",
    "            #saca el tag escondido\n",
    "            comments = soup.find_all(text=lambda text:isinstance(text, Comment))\n",
    "            htm = str([htm for htm in comments if \"div_play_by_play\" in htm]);\n",
    "            if(htm):                          \n",
    "                div = BeautifulSoup(htm,'html.parser')\n",
    "                tbody  = div.find_all(\"tbody\")\n",
    "                rows = tbody[0].find_all('tr', class_ =['top_inning','bottom_inning'])\n",
    "               \n",
    "                for row in rows:\n",
    "                    if row != ['']:\n",
    "                       thtext = row.find_all('th')[0].text                     \n",
    "                       row.insert(0, newtag(div,'td',thtext))\n",
    "                       row.insert(0, newtag(div,'td',visi))\n",
    "                       row.insert(0, newtag(div,'td',home))\n",
    "                       row.insert(0, newtag(div,'td',gamedate))                     \n",
    "\n",
    "                      # print(row)\n",
    "                       cols=row.find_all('td')\n",
    "                       cols=[\" \".join(x.text.replace(',','|').upper().split()) for x in cols]\n",
    "                       file.write(\" , \".join(cols)+'\\n')\n",
    "                       #print(cols)  \n",
    "            file.close  \n",
    "    except ValueError:\n",
    "            file.close \n",
    "            print(\"Error de Valor : load_mlb_games \")\n",
    "            log(get_trace_value(sys.exc_info()),logfile)\n",
    "    except:    \n",
    "            file.close                     \n",
    "            print(\"Error de general : load_mlb_games\") \n",
    "            log(get_trace_value(sys.exc_info()),logfile)\n",
    "\n",
    "#print(load_mlb_schedule(2018)) \n",
    "#score  = 'https://www.baseball-reference.com/boxes/CHN/CHN201810020.shtml'                                            \n",
    "#load_mlb_games(score,2018)\n",
    "\n",
    "\n",
    "for year in range(2010,2015):\n",
    "    sesson  = load_mlb_schedule(year)\n",
    "    cnt = len(sesson)\n",
    "    pr = 1\n",
    "    pb = ProgressBar(total=cnt,prefix='Downloading Games ' + str(year) ,suffix=' ',decimals=2,length=50,fill='▐',zfill=' ')\n",
    "    for score in sesson:\n",
    "        load_mlb_games(score['link'], score['archivo'], score['fecha'])\n",
    "        pb.print_progress_bar(pr)\n",
    "        pr = pr + 1\n",
    "      \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "muuh_Kw_S74y"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "mlb_scraping.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
